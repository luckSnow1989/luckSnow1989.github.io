---
sort: 1
---
# 1.注册中心&配置中心

## 【配置中心】Apollo

Apollo（阿波罗）是一款可靠的分布式配置管理中心，诞生于携程框架研发部，能够集中化管理应用不同环境、不同集群的配置，
配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。

源码： [https://github.com/ctripcorp/apollo](https://github.com/ctripcorp/apollo)

中文文档：[https://www.apolloconfig.com/#/zh/README](https://www.apolloconfig.com/#/zh/README)

https://www.cnblogs.com/andyfengzp/p/7243847.html

## 【配置中心】confd

源码： [ https://github.com/sumory/confd]( https://github.com/sumory/confd)

Confd是一个轻量级的工具，用于管理分布式系统中的配置文件。它通过将配置文件和模板分离来解决配置管理的挑战。
Confd监视由Etcd、Zookeeper、Consul等后端存储的配置更改，然后根据定义的模板生成配置文件，并将其分发到系统中的所有节点。
Confd还支持从命令行或环境变量中读取配置参数，并将其注入到模板中。

在实践中，Confd可以用于管理诸如Nginx、Apache等Web服务器的配置文件，以及运行在Docker或Kubernetes容器中的应用程序的配置文件。
Confd还可以通过与Vault等密钥管理工具的集成来提供安全的配置存储和传输。

## 【注册中心】consul

### 1.介绍
consul-常用命令		https://www.cnblogs.com/xiajq/p/11687270.html

Consul详细命令  	https://blog.csdn.net/y435242634/article/details/78769147

### 2.教程
```text
第一章 consul简介：				https://www.cnblogs.com/java-zhao/p/5356507.html
第二章 consul的安装和启动：		https://www.cnblogs.com/java-zhao/p/5356744.html
第三章 consul服务注册与服务查询：	https://www.cnblogs.com/java-zhao/p/5359806.html
第四章 consul cluster：			https://www.cnblogs.com/java-zhao/p/5375132.html
第五章 consul key/value：		https://www.cnblogs.com/java-zhao/p/5381892.html
第六章 consul UI：				https://www.cnblogs.com/java-zhao/p/5387105.html
附1 consul常用命令+常用选项：	https://www.cnblogs.com/java-zhao/p/5378876.html

启动命令脚本：
	@echo off
	rem 简单启动：	consul agent -dev
	rem 其中X.X.X.X为服务器ip,即可使用http://X.X.X.X:8500 访问ui
	consul.exe agent -server -ui -bootstrap -client 0.0.0.0 -data-dir="D:\java\consul\data" -bind 127.0.0.1
```

consul 是B/C架构。自带 客户端 与 服务端。

### 3.原理

consul 使用的是 Gossip 协议。

Gossip 协议被广泛应用在多个知名项目中，比如 Redis Cluster 集群版，Apache Cassandra，AWS Dynamo。

Consul 天然支持多数据中心，但是多数据中心内的服务数据并不会跨数据中心同步，各个数据中心的 Server 集群是独立的，
Consul 提供了 Prepared Query 功能，它支持根据一定的策略返回多数据中心下的最佳的服务实例地址，使你的服务具备跨数据中心容灾。

Consul 支持以下三种模式的读请求：
- 默认（default）。默认是此模式，绝大部分场景下它能保证数据的强一致性。
  但在老的 Leader 出现网络分区被隔离、新的 Leader 被选举出来的一个极小时间窗口内，可能会导致 stale read。
  这是因为 Consul 为了提高读性能，使用的是基于 Lease 机制来维持 Leader 身份，避免了与其他节点进行交互确认的开销。

- 强一致性（consistent）。强一致性读与 etcd 默认线性读模式一样，每次请求需要集群多数节点确认 Leader 身份，
  因此相比 default 模式读，性能会有所下降。

- 弱一致性（stale)。任何节点都可以读，无论它是否 Leader。可能读取到陈旧的数据，类似 etcd 的串行读。
  这种读模式不要求集群有 Leader，因此当集群不可用时，只要有节点存活，它依然可以响应读请求。

## 【注册中心】etcd

官网: [https://etcd.io/](https://etcd.io/)

### 1.介绍

etcd 是一个一致的分布式键值存储。在分布式系统中主要用作单独的协调服务。并且旨在保存可以完全放入内存的少量数据（默认2G）。

随着CoreOS和Kubernetes等项目在开源社区日益火热，它们项目中都用到的etcd组件作为一个高可用、强一致性的服务发现存储仓库，渐渐为开发人员所关注。

etcd作为一个受到Zookeeper启发的项目，有以下特点。
- 简单：基于HTTP+JSON的API让你用curl命令就可以轻松使用。
- 安全：可选SSL客户认证机制。
- 快速：每个实例每秒支持一千次写操作。
- 可信：使用Raft算法充分实现了分布式。

线性一致性。通过将所有写请求转发到leader上实现。

etcd 使用go开发，属于非常新的框架，没有交给Apache。目前还处于迭代阶段，借由云原生应运而生，后期可期。

### 2.使用教程

入门教程：https://juejin.cn/post/6844904031186321416

基本命令与zk基本一致。

- [etcd学习(1)-etcd的使用场景](https://www.cnblogs.com/ricklz/p/15033193.html)
- [etcd学习(2)-etcd中的watch源码阅读](https://www.cnblogs.com/ricklz/p/15037925.html)
- [etcd学习(3)-grpc使用etcd做服务发现](https://www.cnblogs.com/ricklz/p/15059497.html)
- [etcd学习(4)-centos7中部署etcd](https://www.cnblogs.com/ricklz/p/15074924.html)
- [etcd学习(5)-etcd的Raft一致性算法原理](https://www.cnblogs.com/ricklz/p/15094389.html)
- [etcd学习(6)-etcd实现raft源码解读](https://www.cnblogs.com/ricklz/p/15155095.html)
- [etcd学习(7)-etcd中如何实现线性一致性](https://www.cnblogs.com/ricklz/p/15204381.html)
- [etcd学习(8)-etcd中的lease](https://www.cnblogs.com/ricklz/p/15232204.html)
- [etcd学习(9)-etcd中的存储实现](https://www.cnblogs.com/ricklz/p/15253404.html)
- [etcd学习(10)-etcd对比Consul和zooKeeper如何选型](https://www.cnblogs.com/ricklz/p/15292306.html)


### 3.特性
- Lease 机制

即租约机制（TTL，Time To Live），Etcd 可以为存储的 Key-Value 对设置租约，当租约到期，Key-Value 将失效删除；
同时也支持续约，通过客户端可以在租约到期之前续约，以避免 Key-Value 对过期失效。Lease 机制可以保证分布式锁的安全性，
为锁对应的 Key 配置租约，即使锁的持有者因故障而不能主动释放锁，锁也会因租约到期而自动释放。

- Revision 机制

每个 Key 带有一个 Revision 号，每进行一次事务便加一，因此它是全局唯一的，如初始值为 0，进行一次 put(key, value)，
Key 的 Revision 变为 1，同样的操作，再进行一次，Revision 变为 2；换成 key1 进行put(key1, value)操作，Revision将变为 3；
这种机制有一个作用：通过 Revision 的大小就可以知道写操作的顺序。在实现分布式锁时，多个客户端同时抢锁，
根据 Revision 号大小依次获得锁，可以避免 “羊群效应” （也称“惊群效应”），实现公平锁。

- Prefix 机制

即前缀机制，也称目录机制，例如，一个名为 /mylock 的锁，两个争抢它的客户端进行写操作，
实际写入的Key分别为：key1="/mylock/UUID1",key2="/mylock/UUID2"，其中，UUID表示全局唯一的ID，确保两个Key的唯一性。
很显然，写操作都会成功，但返回的Revision不一样，那么，如何判断谁获得了锁呢？通过前缀“/mylock”查询，
返回包含两个Key-Value对的Key-Value列表，同时也包含它们的Revision，通过Revision大小，客户端可以判断自己是否获得锁，
如果抢锁失败，则等待锁释放（对应的 Key 被删除或者租约过期），然后再判断自己是否可以获得锁。

- Watch 机制

即监听机制，Watch机制支持监听某个固定的Key，也支持监听一个范围（前缀机制），当被监听的Key或范围发生变化，客户端将收到通知；
在实现分布式锁时，如果抢锁失败，可通过Prefix机制返回的Key-Value列表获得Revision比自己小且相差最小的 Key（称为 Pre-Key），
对Pre-Key进行监听，因为只有它释放锁，自己才能获得锁，如果监听到Pre-Key的DELETE事件，则说明Pre-Key已经释放，自己已经持有锁。

### 4.总结

etcd 默认只保存 1000 个历史事件，所以不适合有大量更新操作的场景，这样会导致数据的丢失。

相比于 zookeeper，etcd 使用起来要简单很多。不过要实现真正的服务发现功能，etcd 还需要和其他工具（比如 registrator、confd 等）一起使用来实现服务的自动注册和更新。

相比于zk，etcd 采用 raft 协议作为一致性算法，比基于Paxos的zab协议实现更加简单，选主阶段时间更短。

[ETCD的内存问题与最佳实践](https://coolshell.cn/articles/22242.html)

## 如何设计配置中心

[springboot配置中心](https://code2life.top/2021/05/31/0061-spring-boot-dynamic-config/)

配置中心是微服务系统必不可少的组件之一，乍一看好像没多少技术含量，很多人角色配置中心就是一个kv存储，可是，真的是这样吗？
以Java Spring技术栈为例，主流的配置中心有阿里的Nacos、携程的Apollo、以及Spring Cloud Config Server。我们拆解一下其中共通的技术点：

服务端：
- 认证和权限控制：某个服务可以拿到哪些Key？人员的增删改查权限如何控制？
- 存储层的选型：文件系统，Git仓库，数据库？
- 安全性：传输加TLS，密钥需要落盘加密，本身用来加密密钥的密钥如何安全存储？
- 高可用、数据一致性：多实例部署，甚至跨区域同步，进而又带来分布式存储一致性问题，如何解决？
- 版本控制：修改记录需要保留，随时可能回退到历史版本，另外，灰度版本的配置隔离如何实现？
- 即时发布：配置变更后，实时通知客户端进行变更。

客户端：
- SDK如何兼容不同的技术栈？
- 大量客户端同时启动，如何做并发控制？同时还要尽可能减少额外的请求，对服务启动时间的负面影响？
- 如何实现与本地配置的优先级控制、合并、缓存、变化实时感知？
- 热更新

