---
sort: 1
---
# 1.基础

## 1.介绍

- 英文官网：[http://www.redis.io](http://www.redis.io)
- 中文官网：[http://www.redis.cn](http://www.redis.cn)
- Redis组织官网（包含redis、RedisJson、RedisSearch等项目）：[https://redis.com](https://redis.com)

推荐书籍
- 《Redis入门指南（第2版）》
- 《Redis设计与实现》
- 《Redis开发与运维》
- 《Redis实战》
- 《Redis深度历险：核心原理与应用实践》
- 《Redis使用手册》
- 《Redis设计与源码分析》
- 《Redis 4.x Cookbook中文版》
- 《深入理解Redis》
- 《Redis Essentials》
- 《Redis核心原理与实践》


**1.redis是什么**
> redis是开源的，BSD许可，高级的key-value存储系统。可以用来存储字符串、哈希结构、列表、集合，因此常用来提供数据结构服务

**2.使用场景**

Redis在国内各大公司都能看到其身影，比如我们熟悉的新浪，阿里，腾讯，百度，美团，小米等。
学习 Redis，这几方面尤其重要：Redis 客户端、Redis 高级功能、Redis 持久化和开发运维常用问题探讨、Redis 复制的原理和优化策略、Redis分布式解决方案等。
- String：缓存、限流、计数器、分布式锁、分布式Session
- Hash：存储用户信息、用户主页访问量、组合查询
- List：微博关注人时间轴列表、简单队列
- Set：赞、踩、标签、好友关系
- Zset：排行榜

## 2.安装

官方安装教程：[https://developer.redis.com/create](https://developer.redis.com/create)

**目录结构**
- redis-benchmark 性能测试，用以模拟同时由N个客户端发送M个SET/GET查询 (类似于 Apache 的ab 工具)
- redis-check-aof aof日志文件检测工(比如断电造成日志损坏,可以检测并修复)
- redis-check-dump rdb快照文件检测工具
- redis-cli 命令行连接的客户端
- redis-server Redis服务进程

### 2.1.单机

#### 2.1.1.Linux安装
下载地址
- 官网：[http://download.redis.io/releases/](http://download.redis.io/releases/)
- 中文网：[http://www.redis.cn/download.html](http://www.redis.cn/download.html)

下载最新版或者最新release版（redis只有3.0以上的版本开始支持集群），这里我们下载的是：redis-6.0.6.tar.gz，

![image](img/1.redis安装&命令/media/image2.png)

```text
1.将压缩包存放在每个服务器的目录是：/usr/local
2.到该目录解压安装包
  tar -zxvf redis-6.0.6.tar.gz
3.进入redis目录
  cd redis-6.0.6
4.编译项目
  make
  显示编译成功即可
5.安装
    安装到指定的目录,比如 /usr/local/redis
    make PREFIX=/usr/local/redis install
6.启动项目
  注意这里必须指定redis.conf，否则都是默认的配置
  ./bin/redis-server redis.conf

7.测试端口是否正常
    netstat -nlt | grep 6379
    tcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN
    tcp6 0 0 :::6379 :::* LISTEN
    ip为0.0.0.0即可远程访问，要是127.0.0.1或者localhost就不行了

8.使用ip访问redis
  ./reids-cli -h 192.168.3.101 -p 6379
```

**开启远程访问**：redis 3.2 以上的版本上入了新特性，默认只支持本地连接。想要远程连接需要以下操作

```shell
vim redis.conf

# 1.此处注释掉、或者将bind 127.0.0.1改为 0.0.0.0、 或者指定ip可供远程连接
bind 0.0.0.0

# 2.将保护模式 yes改为no 可供远程连接
protected-mode no

# 3.此处守护进程改为yes 可供后台启动
daemonize yes

# 4 使用密码连接，提高安全性
requirepass 123456
```

#### 2.1.2.window安装

官方不提供windows版本。市面上比较可靠的有两个。

- 微软移植版：[https://github.com/microsoftarchive/redis](https://github.com/microsoftarchive/redis)
最高只有3.2。
  
- 个人开发编译：[https://github.com/tporadowski/redis/releases](https://github.com/tporadowski/redis/releases)
最高是5.0。推荐使用这个。

### 2.2.主从

1、安装多个Redis
- 7001 master
- 7002 slaveof-0
- 7002 slaveof-1

2、修改redis.conf配置文件

```shell
#1.修改master
port 7001
bind 0.0.0.0
protected-mode no
daemonize yes

# 2.修改slaveof
port 7002
bind 0.0.0.0
protected-mode no
daemonize yes
# 增加行
slaveof 127.0.0.1 7001   

# 3.修改slaveof
port 7003
bind 0.0.0.0
protected-mode no
daemonize yes
# 增加行
slaveof 127.0.0.1 7001
```

3、启动服务，查看从redis是否存在主redis的数据

```shell
# 1.master 的日志
# 初始化Redis服务
[15500] 02 Dec 20:29:51.727 # Server initialized
# 加载rdb数据，耗时0.032s
[15500] 02 Dec 20:29:51.759 * DB loaded from disk: 0.032 seconds
# 开始接受数据
[15500] 02 Dec 20:29:51.759 * Ready to accept connections
# slave 启动了，开始订阅 master的数据，进行同步
[15500] 02 Dec 20:30:28.431 * Replica 127.0.0.1:7002 asks for synchronization
# 全量同步
[15500] 02 Dec 20:30:28.431 * Full resync requested by replica 127.0.0.1:7002
# 使用BGSAVE
[15500] 02 Dec 20:30:28.431 * Starting BGSAVE for SYNC with target: disk
# 开始dump数据，使用子进程 15024
[15500] 02 Dec 20:30:28.476 * Background saving started by pid 15024
# 子进程操作成功
[15500] 02 Dec 20:30:28.688 # fork operation complete
[15500] 02 Dec 20:30:28.707 * Background saving terminated with success
# 向slave同步数据并成功
[15500] 02 Dec 20:30:28.714 * Synchronization with replica 127.0.0.1:7002 succeeded

# 2.slaveof 的日志
[23504] 02 Dec 20:30:28.398 # Server initialized
[23504] 02 Dec 20:30:28.429 * DB loaded from disk: 0.031 seconds
[23504] 02 Dec 20:30:28.429 * Ready to accept connections
# 连接master
[23504] 02 Dec 20:30:28.430 * Connecting to MASTER 127.0.0.1:7001
# 开始同步数据
[23504] 02 Dec 20:30:28.430 * MASTER <-> REPLICA sync started
# 使用非阻塞的方式同步(也就是psync函数)
[23504] 02 Dec 20:30:28.430 * Non blocking connect for SYNC fired the event.
# 同步过程中，使用ping的方式去保持连接
[23504] 02 Dec 20:30:28.430 * Master replied to PING, replication can continue...
# 不进行部分同步
[23504] 02 Dec 20:30:28.431 * Partial resynchronization not possible (no cached master)
# 开始进行全量同步，接收主节点的 同步副本的id 和 偏移量offset
[23504] 02 Dec 20:30:28.476 * Full resync from master: b1900a284495a00827d662583d9848c4c484061e:0
# 开始接受master的数据
[23504] 02 Dec 20:30:28.711 * MASTER <-> REPLICA sync: receiving 1054786 bytes from master
# 清空自己的旧数据
[23504] 02 Dec 20:30:28.715 * MASTER <-> REPLICA sync: Flushing old data
# 加载master同步过来的rdb
[23504] 02 Dec 20:30:28.724 * MASTER <-> REPLICA sync: Loading DB in memory
# 同步完成
[23504] 02 Dec 20:30:28.760 * MASTER <-> REPLICA sync: Finished with success
```

4、主从切换，master宕机后，手动切换
```shell
# 7002 作为新的master，执行下面的命令
127.0.0.1:7002> slaveof no one  # 本机关闭 slaveof
127.0.0.1:7002> config set slave-read-only no    # 关闭只读的状态

# 7003 还是slave，但是需要修改 master为7002
127.0.0.1:7003> slaveof 127.0.0.1:7002
```

5、备注
- 需要自己创建从redis相关目录
- 从redis只有读取权限
- 主故障后只能手动切换

### 2.3.哨兵

1、安装多个Redis
- 7001 master     不需要主从的配置
- 7002 slaveof-0  不需要主从的配置
- 7002 slaveof-1  不需要主从的配置
- 6000 sentinel

2、修改哨兵的配置文件
```shell
port 6000
bind 0.0.0.0
protected-mode no
daemonize yes

# 监视一个名为mymaster的主redis实例，地址是：127.0.0.1:7001，这个实例至少由1个哨兵判断为主观下线，就会切换主从
# 一般我们配置了3个哨兵，就可以配置2个同步切换就切换，如果只有1个哨兵，就必须配置1，否则永远不能切换了
sentinel monitor mymaster 127.0.0.1 7001 1
# 指定了Sentinel认为Redis实例已经失效所需的毫秒数。当 实例超过该时间没有返回PING，或者直接返回错误，
# 那么Sentinel将这个实例标记为主观下线。只有一个 Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移：
# 只有在足够数量的Sentinel都将一个实例标记为主观下线之后，实例才会被标记为客观下线，这时自动故障迁移才会执行
sentinel down-after-milliseconds mymaster 5000
# 指定了在执行故障转移时，最多可以有多少个从Redis实例在同步新的主实例，在从Redis实例较多的情况下这个数字越小，同步的时间越长，
# 完成故障转移所需的时间就越长
sentinel parallel-syncs mymaster 1
# 如果在该时间（ms）内未能完成failover操作，则认为该failover失败
sentinel failover-timeout mymaster 15000
#**认证密码**
sentinel auth-pass mymaster 123            
# Generated by CONFIG REWRITE
sentinel config-epoch mymaster 144
sentinel leader-epoch mymaster 144
#**从redis**
sentinel known-slave mymaster 127.0.0.1 7002
sentinel known-slave mymaster 127.0.0.1 7003 
sentinel current-epoch 144
```

3、启动服务哨兵。需要增加一个特别的参数

```shell
# 启动服务 
./bin/redis-server redis.conf --sentinel

[25932] 02 Dec 21:39:16.599 # Sentinel ID is 5d478594edf2f5bf2f3c446741b7c613aaa88444
[25932] 02 Dec 21:39:16.600 # +monitor master mymaster 127.0.0.1 7001 quorum 1
[25932] 02 Dec 21:39:26.679 * +convert-to-slave slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7001
[25932] 02 Dec 21:39:26.679 * +convert-to-slave slave 127.0.0.1:7003 127.0.0.1 7002 @ mymaster 127.0.0.1 7001

## 当master宕机
# 主观下线
[9632] 02 Dec 21:51:30.318 # +sdown master mymaster 127.0.0.1 7001
# 法定人数是否符合阈值，到达的话就客观下线
[9632] 02 Dec 21:51:30.318 # +odown master mymaster 127.0.0.1 7001 #quorum 1/1
# 开启新朝代
[9632] 02 Dec 21:51:30.318 # +new-epoch 145
# 尝试去掉配置文件中的master
[9632] 02 Dec 21:51:30.318 # +try-failover master mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:30.321 # +vote-for-leader 5d478594edf2f5bf2f3c446741b7c613aaa88444 145
[9632] 02 Dec 21:51:30.321 # +elected-leader master mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:30.321 # +failover-state-select-slave master mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:30.411 # +selected-slave slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:30.411 * +failover-state-send-slaveof-noone slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:30.490 * +failover-state-wait-promotion slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:31.113 # +promoted-slave slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:31.114 # +failover-state-reconf-slaves master mymaster 127.0.0.1 7001
[9632] 02 Dec 21:51:31.172 # +failover-end master mymaster 127.0.0.1 7001
# 选举出新的master
[9632] 02 Dec 21:51:31.172 # +switch-master mymaster 127.0.0.1 7001 127.0.0.1 7002
# 切换master
[9632] 02 Dec 21:51:31.172 * +slave slave 127.0.0.1:7001 127.0.0.1 7001 @ mymaster 127.0.0.1 7002
[9632] 02 Dec 21:51:36.234 # +sdown slave 127.0.0.1:7001 127.0.0.1 7001 @ mymaster 127.0.0.1 7002
```

4、备注
- 如果主redis挂了,哨兵回去修改从redis的配置文件，和哨兵本身配置文件，将从的redis修改为主的redis
- 一般选择3个哨兵（哨兵高可用的最低配置，允许1个哨兵故障）、一主一备。

### 2.4.cluster集群
#### 2.4.1.Linux安装过程

以下是在单机上配置6节点集群

1.创建节点（当前位置在redis-3.2.1）

```shell
mkdir redis-cluster
mkdir 7000 7001 7002 7003 7004 7005
```

然后将redis.conf拷贝到各个节点：

```shell
cp /redis.conf ../7000
cp /redis.conf ../7001
cp /redis.conf ../7002
cp /redis.conf ../7003
cp /redis.conf ../7004
cp /redis.conf ../7005
```

2.修好配置文件

```shell
daemonize    yes                          //redis后台运行
pidfile  /var/run/redis_7000.pid          //pidfile文件对应7000,7002,7003
port  7000                                //端口7000,7002,7003
cluster-enabled  yes                      //开启集群  把注释#去掉
cluster-config-file  nodes_7000.conf      //集群的配置  配置文件首次启动自动生成 7000,7001,7002
cluster-node-timeout  5000                //请求超时  设置5秒够了
appendonly  yes                           //aof日志开启  有需要就开启，它会每次写操作都记录一条日志
bind 192.168.200.140 					  //绑定ip	bind需要绑定当前服务器的IP
```

3.启动redis

```shell
./redis-server ../7000/redis.conf
./redis-server ../7001/redis.conf
./redis-server ../7002/redis.conf
./redis-server ../7003/redis.conf
./redis-server ../7004/redis.conf
./redis-server ../7005/redis.conf

./redis-cli -h ip -p port shutdown #终止服务
ps -ef | grep redis   #查看是否启动成功
netstat -tnlp | grep redis #可以看到redis监听端口
```

可以编写启动脚本（&是在后台启动redis）

```shell
./redis-server ../7000/redis.conf &
./redis-server ../7001/redis.conf &
./redis-server ../7002/redis.conf &
./redis-server ../7003/redis.conf &
./redis-server ../7004/redis.conf &
./redis-server ../7005/redis.conf &
```

4.创建集群 需要ruby环境

之前redis节点已经准备好了，但是要将redis串联起来就得需要redis的一个工具：redis-trib.rb

Ubuntu ：

```shell
sudo apt-get install zlib1g zlib1g-dev zlib1g-dpg
sudo apt-get install ruby-full
```

CentOS：

```shell
yum -y install ruby ruby-devel rubygems rpm-build
sudo yum install ruby
```

安装 GEM，Redis 的 ruby 支持环境（2.0以上自带gem）

切换源：[https://rubygems.org](https://rubygems.org)

由于 GFW的问题， GEM 的源在国内不可用，所以使用淘宝的映像：

使用cmd命令：

添加：

```gem sources -a https://ruby.taobao.org```

查看已存在的源：

```gem sources -l```

删除被墙的源：

```gem sources -r https://rubygems.org/```

在用gem命令安装redis接口，gem是ruby的一个工具包

```gem install redis```

5.下载redis-trib.rb，并启动集群(redis-trib.rb存放位置不限)

需要权限：chmod 777 redis-trib.rb

```shell
./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
```

注意：

--replicas 1 表示自动为每个master节点分配一个slave节点 ，如果想手动指定 Slave , 将该值变为 0 即可， 地址列表中，只需要3个实例即可

防火墙一定要开放监听的端口，否则会创建失败

由于使用的是 6个实例，自动分配 Slave ，所以前3个为 master , 后3 个为 slave， 并确定3个主节点的 slots 范围。

在运行过程中会提示：Can I set the above configuration? (type 'yes' to accept): yes //输入yes

```shell
运行./redis-trib.rb check 127.0.0.1:7000
```

如果确认没有问题， 输入 yes

如果群集创建成功， 会输出 OK XXXXX

如果出现：err slot xxx is already busy, 请删除 appendonly.aof 及 nodes-xxx.conf (cluster-config-file 所指的文件) 文件

6.测试

```shell
./redis-cli -c -p 7000
```

必须使用-c才能连接到真正的集群上，否则只是连接到普通的单机上

7.总结

- redis cluster在设计的时候，就考虑到了去中心化、去中间件，也就是说，集群中的每个节点都是平等关系，都是对等的，每个节点都
- 保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任
- 意一个节点，就可以获取到其他节点的数据。

#### 2.4.2.Ruby安装

安装依赖：

``` sudo apt-get install zlib1g zlib1g-dev zlib1g-dpg ```


安装 GEM，Redis 的 ruby 支持环境（2.0以上自带gem）

切换源：[https://rubygems.org](https://rubygems.org)

由于 GFW的问题， GEM 的源在国内不可用，所以使用淘宝的映像：

使用cmd命令：

添加：

```gem sources -a https://ruby.taobao.org```

查看已存在的源：

```gem sources -l```

删除被墙的源：

```gem sources -r https://rubygems.org/```

#### 2.4.3.集群命令

- 集群
    - cluster info ：打印集群的信息
    - cluster nodes ：列出集群当前已知的所有节点（node），以及这些节点的相关信息。

- 节点
    - cluster meet <ip> <port> ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。
    - cluster forget <node_id> ：从集群中移除 node_id 指定的节点。
    - cluster replicate <node_id> ：将当前节点设置为 node_id 指定的节点的从节点。
    - cluster saveconfig ：将节点的配置文件保存到硬盘里面。

- 槽(slot)
    - cluster addslots <slot> [slot ...] ：将一个或多个槽（slot）指派（ assign）给当前节点。
    - cluster delslots <slot> [slot ...]：移除一个或多个槽对当前节点的指派。
    - cluster flushslots：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。
    - cluster setslot <slot> node <node_id> ：将槽 slot 指派给node_id指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽>，然后再进行指派。
    - cluster setslot <slot> migrating <node_id> ：将本节点的槽slot 迁移到 node_id 指定的节点中。
    - cluster setslot <slot> importing <node_id> ：从 node_id指定的节点中导入槽 slot 到本节点。
    - cluster setslot <slot> stable ：取消对槽 slot 的导入（import）或者迁移（ migrate）。

- 键
    - cluster keyslot <key> ：计算键 key 应该被放置在哪个槽上。
    - cluster countkeysinslot <slot> ：返回槽 slot目前包含的键值对数量。
    - cluster getkeysinslot <slot> <count> ：返回 count 个 slot槽中的键

#### 2.4.4.实现原理

Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。
redis cluster默认分配了 16384 个 slot，当我们 set 一个 key 时，会用CRC16算法来取模得到所属的slot，
然后将这个 key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) %16384。
所以我们在测试的时候看到 set 和 get的时候，直接跳转到了7000端口的节点。

Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步。
当读取数据时，也根据一致性哈希算法到对应的master 节点获取数据。只有当一个 master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。

需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。

#### 2.4.5.常见问题

##### 2.4.5.1.创建集群卡住

以上是同一台机器上的群集部署方案，同一台虚拟机，使用不同的实例,创建群集时，一路顺利。

但是将实例部署到不同的机器上，我分别在6台虚拟机上安装了 Redis,但一开始创建群集的时候，就卡在这里：

```shell
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster

Waiting for the cluster to join....................
```

一直在这个 Waiting for the cluster to join 这里。。。

用Redis自带的检测工具检查

```shell
redis-trib.rb check 192.168.18.111:6379
[ERR] Not all 16384 slots are covered by nodes
```

具体的就是某台 master 上的 sloats 是 0

用客户端连接到那个没有分配 sloat 的 redis 实例，发送以下命令：

```shell
cluster meet 192.168.18.111 6379
```

回头在用 Redis-trib.rb check 检查， 发现

```shell
[OK] All 16384 slots covered.
```

但是群集的创建还是卡在那个 waiting 上 ,继续在其它节点上发送 cluster meet 命令，回头在用 redis-trib.rb check ,
神奇的 Not all 16384 slots are covered by nodes 居然又来了。

将那个slots 为 0的实例做为 slave（放到参数列表的最后），在创建，顺利通过！这个问题真是神奇啊！

##### 2.4.5.2.集群关闭后启动失败

Redis cluster 最小集群为6节点（3master 3slave），挂掉任意一个整个集群都会宕机。

redis cluster集群中的节点基本上都对等的，没有管理节点。如果要让所有节点都关闭，只能关闭进程了：pkill -9 redis

把所有集群都关闭，然后在重新启动，会报以下错误

```shell
# redis-trib.rb create --replicas 1
xxx.xxx.xxx.xxx:6379。。。。。。。。。
会报以下错误，

[ERR] Node 192.168.10.219:6379 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.
```

第一次启动集群时，/etc/redis下只有redis.conf，所以我想把除了redis.conf外的其他文件全部删除，在启动肯定是可以的，但是集群是有数据的，所以保留了配置文件和数据文件。

```shell
# cd /etc/redis
# rm -f *.aof nodes-63*
# ll //保留了配置文件和数据文件

总用量 204
-rw-r--r-- 1 root root 18 5月 7 11:21 dump-6379.rdb
-rw-r--r-- 1 root root 18 5月 7 11:21 dump-6380.rdb
-rw-r--r-- 1 root root 18 5月 7 11:21 dump-6381.rdb
-rw-r--r-- 1 root root 41412 4月 30 23:30 redis-6379.conf
-rw-r--r-- 1 root root 41412 4月 30 23:39 redis-6380.conf
-rw-r--r-- 1 root root 41412 4月 30 23:39 redis-6381.conf
```

这样是可以启动的，但是原来的数据还是丢失了，不知道是自己的想法不对，还是redis cluster根本没考虑，所有节点都会挂掉的情况。


### 2.5.容器化部署

[https://developer.redis.com/create/docker/redis-on-docker](https://developer.redis.com/create/docker/redis-on-docker)

[https://zhuanlan.zhihu.com/p/70110697](https://zhuanlan.zhihu.com/p/70110697)

https://blog.csdn.net/qq_24958783/article/details/107541425

```shell
docker run -d --name myredis -p 6379:6379 --privileged=true -v \
    /usr/local/redis/data/:/data -v  \
    /usr/local/redis/redis.conf:/etc/redis/redis.conf redis:6.0.6 \
    redis-server /etc/redis/redis.conf --requirepass "pwd123"
```

打开客户端：

```shell
docker exec -it myredis redis-cli
```

配置文件：

- daemonize no 如果为YES 会的导致 redis 无法启动，因为后台会导致docker无任务可做而退出。
- 注释掉：bind 127.0.0.1
- protected-mode no
- appendonly yes

需要特别注意的：
- 数据的安全性，挂载本地数据盘到容器中，用来保存数据，防止容器重启后数据丢失
- 使用默认配置启动实例，所以我们需要自己手动挂载配置文件到容器中，并指定加载该配置文件
- 特殊配置，比如设置密码，可以在镜像后面增加Redis自己的配置。

### 2.6.其他集群方案

有一部分在客户端程序上面实现的分片功能。【现在几乎已经被舍弃了】

### 2.7.其他版本Redis

这些年，涌现了不少类似的 Redis 兼容型内存数据存储系统，例如 KeyDB、Skytable，Dragonfly，tendis。
作为一项基础性技术，每隔段时间总有人跳出来，想要替 Redis 换套新架构。

主流的方案还是使用Redis官方提供的集群方案。

#### 2.7.1.Tendis

Tendis存储版是腾讯互娱CROS DBA团队 & 腾讯云数据库团队自主设计和研发的开源分布式高性能KV存储。
完全兼容redis协议，并使用rocksdb作为存储引擎。用户可以通过redis client访问Tendis存储版，几乎不用修改代码。
同时，Tendis存储版支持远超内存的磁盘容量，可以大大降低用户的存储成本。

- 官网地址： [http://tendis.cn](http://tendis.cn)
- 简单介绍： [https://mp.weixin.qq.com/s/fOt05aCA_8cn9LIskC0noQ](https://mp.weixin.qq.com/s/fOt05aCA_8cn9LIskC0noQ)

使用编译方式的tendis，官方文档不全，可能在编译的过程失败很多次。可能还需要安装：

```shell
# gcc5.5.0 的依赖如下
yum -y install bzip2
yum install -y gcc
yum install -y binutils
yum install -y gzip gawk gmake tar
yum install -y perl // darwin
yum install -y zip unzip // libgc
```

#### 2.7.2.Dragonfly

新型内存数据库，兼容 Memcached 和 Redis 协议
[介绍](https://mp.weixin.qq.com/s/x9B615N2LZHiRl8jFHcKrA)

压测工具，memtier_benchmark

#### 2.7.3.Twemproxy
twitter开源的Redis proxy 工具。
- 源码：[https://github.com/twitter/twemproxy](https://github.com/twitter/twemproxy)
- [Redis+Twemproxy+HAProxy集群](https://blog.csdn.net/shmilychan/article/details/73433804)
- [Redis 集群之Redis+Twemproxy方案](https://www.jianshu.com/p/d94728fc8a91)

缺点：
- 虽然可以动态移除节点，但该移除节点的数据就丢失了。
- redis集群动态增加节点的时候，twemproxy不会对已有数据做重分布
- 性能上损耗

#### 2.7.4.Codis

豌豆荚开源的分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别，
上层应用可以像使用单机的 Redis 一样使用，Codis 底层会处理请求的转发, 不停机的数据迁移等工作，所有后边的一切事情,
对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的Redis 服务。

- 源码：[https://github.com/CodisLabs/codis](https://github.com/CodisLabs/codis)
- Codis的原理以及部署：[https://blog.csdn.net/ymeng9527/article/details/99658061](https://blog.csdn.net/ymeng9527/article/details/99658061)

源码已经停留在2018年，最新的codis基于Redis3.2.8分支。自从Redis官方提供了高可用方案后，逐步被抛弃。

## 3.基础使用

常见命令参考：[http://www.redis.cn/commands.html](http://www.redis.cn/commands.html)

快速命令查找
```shell
1.启动:redis-server redis.conf
2.关闭:redis-cli [-a 密码] shutdown
3.连接操作相关的命令
	auth 简单密码认证 #密码登陆(如果有密码)
    ping #测试服务器是否可用
    echo "some content" #测试服务器是否正常交互
    select 0/1/2... #选择数据库
    quit：关闭连接（connection）
4.持久化
    bgsave 后台开启子进程dump数据
    save 阻塞进程dump数据
	lastsave：返回上次成功将数据保存到磁盘的Unix时戳
	shundown：将数据同步保存到磁盘，然后关闭服务
6.对key操作的命令
	exists(key)：确认一个key是否存在
	del(key)：删除一个key
	type(key)：返回值的类型
	keys(pattern)：返回满足给定pattern的所有key
	randomkey：随机返回key空间的一个
	keyrename(oldname, newname)：重命名key
	dbsize：返回当前数据库中key的数目
	expire：设定一个key的活动时间（s）
	ttl：获得一个key的活动时间
	select(index)：按索引查询,redis有16个db，默认使用db0，使用select 选择使用的数据库
	move(key, dbindex)：移动当前数据库中的key到dbindex数据库
	flushdb：删除当前选择数据库中的所有key
	flushall：删除所有数据库中的所有key
7.对String操作的命令
	set(key, value)：给数据库中名称为key的string赋予值value
	get(key)：返回数据库中名称为key的string的value
	getset(key, value)：给名称为key的string赋予上一次的value
	mget(key1, key2,…, key N)：返回库中多个string的value
	setnx(key, value)：添加string，名称为key，值为value
	setex(key, time, value)：向库中添加string，设定过期时间time
	mset(key N, value N)：批量设置多个string的值
	msetnx(key N, value N)：如果所有名称为key i的string都不存在
	incr(key)：名称为key的string增1操作
	incrby(key, integer)：名称为key的string增加integer
	decr(key)：名称为key的string减1操作
	decrby(key, integer)：名称为key的string减少integer
	append(key, value)：名称为key的string的值附加value
	substr(key, start, end)：返回名称为key的string的value的子串
8.对List操作的命令
	rpush(key, value)：在名称为key的list尾添加一个值为value的元素
	lpush(key, value)：在名称为key的list头添加一个值为value的 元素
	llen(key)：返回名称为key的list的长度
	lrange(key, start, end)：返回名称为key的list中start至end之间的元素
	ltrim(key, start, end)：截取名称为key的list
	lindex(key, index)：返回名称为key的list中index位置的元素
	lset(key, index, value)：给名称为key的list中index位置的元素赋值
	lrem(key, count, value)：删除count个key的list中值为value的元素
	lpop(key)：返回并删除名称为key的list中的首元素
	rpop(key)：返回并删除名称为key的list中的尾元素
	blpop(key1, key2,… key N, timeout)：lpop命令的block版本。
	brpop(key1, key2,… key N, timeout)：rpop的block版本。
	rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部
9.对Set操作的命令
	sadd(key, member)：向名称为key的set中添加元素member
	srem(key, member) ：删除名称为key的set中的元素member
	spop(key) ：随机返回并删除名称为key的set中一个元素
	smove(srckey, dstkey, member) ：移到集合元素
	scard(key) ：返回名称为key的set的基数
	sismember(key, member) ：member是否是名称为key的set的元素
	sinter(key1, key2,…key N) ：求交集
	sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合
	sunion(key1, (keys)) ：求并集
	sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合
	sdiff(key1, (keys)) ：求差集
	sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合
	smembers(key) ：返回名称为key的set的所有元素
	srandmember(key) ：随机返回名称为key的set的一个元素
10.对Hash操作的命令
	hset(key, field, value)：向名称为key的hash中添加元素field
	hget(key, field)：返回名称为key的hash中field对应的value
	hmget(key, (fields))：返回名称为key的hash中field i对应的value
	hmset(key, (fields))：向名称为key的hash中添加元素field 
	hincrby(key, field, integer)：将名称为key的hash中field的value增加integer
	hexists(key, field)：名称为key的hash中是否存在键为field的域
	hdel(key, field)：删除名称为key的hash中键为field的域
	hlen(key)：返回名称为key的hash中元素个数
	hkeys(key)：返回名称为key的hash中所有键
	hvals(key)：返回名称为key的hash中所有键对应的value
	hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value
11.对Zset操作的命令
12.服务端操作命令
    time 返回时间戳+微秒
    dbsize 返回key的数量
    bgrewriteaof 重写aof
    slaveof host port 做host port的从服务器(数据清空,复制新主内容)
    slaveof no one 变成主服务器(原数据不丢失,一般用于主服失败后)
    flushdb 清空当前数据库的所有数据
    flushall 清空所有数据库的所有数据(误用了怎么办?)
    shutdown [save/nosave] 关闭服务器,保存数据,修改AOF(如果设置)
    slowlog get 获取慢查询日志
    slowlog len 获取慢查询日志条数
    slowlog reset 清空慢查询
    info 查看服务信息
    config get 选项(支持*通配)
    config set 选项 值
    config rewrite 把值写到配置文件
    config restart 更新info命令的信息
    debug object key #调试选项,看一个key的情况
    debug segfault #模拟段错误,让服务器崩溃
    object key (refcount|encoding|idletime)
    monitor #打开控制台,观察命令(调试用)
    client list #列出所有连接
    client kill #杀死某个连接 CLIENT KILL 127.0.0.1:43501
    client getname #获取连接的名称 默认nil
    client setname "名称" #设置连接名称,便于调试	
```

### 3.1.基础结构 
String、Hash、List、Set、ZSet

### 3.2.复杂结构

#### 3.2.1.Bitmap 位图
[一看就懂 详解redis的bitmap](https://zhuanlan.zhihu.com/p/480386998)

在string的基础上进行位操作，可以实现节省空间的数据结构。非常时候用在需要记录是否的场景，比如：是否签到、是否登录

如果是放在表中 1:表急剧增大,2:要用group ,sum运算,计算较慢。解决方案: 位图法 bit-map

语法
```shell
# offset 就是第几位,string 最大512MB，所有offset最大就是 512*1024*1024=536,870,912 （5.37亿） 
# value只有0和1，否则就报错了
setbit key offset value

# 查看 某个位置的值
getbit key offset

# 统计为1的数量
bitcount key [begin end]

# 多个key进行异或非运算
# operation 是操作，参数有and , or, xor, not 
# destkey,报错运算的结果，方便后面继续使用。
bitop operation destkey k1 [k2 ...]

# 我们使用type命令查看，结果是string，所以我们可以使用get命令操作。
type Bitmap的key
```

如上例,优点:
1. 节约空间, 1亿人每天的登陆情况,用1亿bit,约1200WByte,约10M的字符就能表示
2. 计算方便

#### 3.2.2.Hyperloglog

用于估计一个 set中元素数量的概率性的数据结构。相比bitMap更加能保存大量的数据，占用更小的内存空间。 HyperLogLog是一种概率数据结构，用来估算数据的基数。。

使用 Redis 统计集合的基数一般有三种方法，分别是使用 Redis 的 HashMap，BitMap 和 HyperLogLog。
前两个数据结构在集合的数量级增长时，所消耗的内存会大大增加，但是HyperLogLog 则不会。

Redis 的 HyperLogLog通过牺牲准确率来减少内存空间的消耗，只需要12K内存，在标准误差0.81%的前提下，能够统计2^64个数据。
所以HyperLogLog 是否适合在比如统计日活月活此类的对精度要不不高的场景。 这是一个很惊人的结果，以如此小的内存来记录如此大数量级的数据基数。

常使用的命令有三个： pfadd pfcount pfmarge

```shell
# 向一个key中添加元素
> pfadd key1 v1 v2 v3 v4
(Integer) 1

# 统计key中元素的个数
> pfcount key1
(Integer) 4

# 向一个新key中添加元素
> pfadd key2 v4 v5 v6 v7
(Integer) 1

# 合并两个key的数据
> pfmarge key1 key2

# 统计key中元素的个数
> pfcount key1
(Integer) 7
```

- 优点：占用的内存很小，一个key只占用12KB。适用于需要统计多种数据的场景
- 缺点：无法确定一个数据是否已经存在过（也就是不能反查询）；存在误差。

#### 3.2.3.Geo

[https://www.runoob.com/redis/redis-geo.html](https://www.runoob.com/redis/redis-geo.html)

### 3.3.key操作命令

#### 3.3.1.Keys

keys命令的作用是列出Redis所有的key,该命令的时间复杂度为O(N)，N随着Redis中key的数量增加而增加，因此Redis有大量的key，
keys命令会执行很长时间，而由于Redis是单线程，某个命令耗费过长时间，则会导致后面的的所有请求无法得到响应。
因此，千万不要在生产服务器上使用keys命令。

keys pattern 查询相应的key，在redis里,允许模糊查询key

有3个通配符 *, ? ,[]
- *: 通配任意多个字符
- ?: 通配单个字符
- []: 通配括号内的某1个字符

#### 3.3.2.Scan

使用keys指令可以扫出指定模式的key列表。但是由于redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。

这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

scan 游标位置 match 表达式 count 每次迭代的数量

```shell
scan 0 match Map count 10
```

Scan可以理解为
- 将redis所有的key当做一个列表
- 游标位置，0表示从头开始，1表示，从第count*1的位置开始。
- 每次迭代的数量，count默认=10，可以看做每次迭代里面有5个元素。
- 这两个变量结合起来可以看做是一个分页的功能，一个是第几页，另一个是每页的数量
- 注意：这个命令需要自己手动遍历，一般使用程序辅助实现

### 3.4.info信息

```shell
# Server
redis_version:6.0.6
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:cc183340fc53ad9b
redis_mode:standalone
os:Linux 4.19.0-amd64-desktop x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:8.3.0
process_id:24070
run_id:fe1c962542abf778c67e85a84333b6ead6981c5a
tcp_port:6379
uptime_in_seconds:3140
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:9003260
executable:/data/home/zhangxue/java/redis-6.0.6/./bin/redis-server
config_file:/data/home/zhangxue/java/redis-6.0.6/redis.conf

# Clients
connected_clients:3
client_recent_max_input_buffer:2
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0


# Memory
# 1.Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即 swap）；used_memory_human 只是显示更友好。
used_memory:454906944
used_memory_human:433.83M

# 2.Redis 进程占据操作系统的内存（单位是字节），与 top 及 ps 命令看到的值是一致的。
# 除了分配器分配的内存之外，used_memory_rss 还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。
used_memory_rss:539422720
used_memory_rss_human:514.43M

# 3.
used_memory_peak:468242000
used_memory_peak_human:446.55M

# 4.操作系统本身的内存大小
total_system_memory:67559575552
total_system_memory_human:62.92G

# 5.lua脚本占用内容的大小
used_memory_lua:37888
used_memory_lua_human:37.00K

# 6.Redis被限制使用的内存上限
maxmemory:4294967296
maxmemory_human:4.00G

# 7.内存达到上限后的回收策略
maxmemory_policy:volatile-lru

# 7.内存碎片比率，该值是 used_memory_rss / used_memory 的比值。
#   mem_fragmentation_ratio < 1，说明 Redis 使用了虚拟内存，说明可能内存不够了，由于虚拟内存的媒介是磁盘，比内存速度要慢很多。
#   mem_fragmentation_ratio 一般大于 1，且该值越大，内存碎片比例越大；
mem_fragmentation_ratio:1.19

# 8.Redis使用的内存分配器
# 指定编译时Redis使用的内存分配器：libc、jemalloc、tcmalloc，默认是jemalloc
mem_allocator:jemalloc-4.0.3

used_memory_peak_perc:33.85%
used_memory_overhead:1735678
used_memory_startup:328016
used_memory_dataset:1598218
used_memory_dataset_perc:53.17%
allocator_allocated:3375344
allocator_active:3706880
allocator_resident:6295552
total_system_memory:16283783168
total_system_memory_human:15.17G
used_memory_scripts:0
used_memory_scripts_human:0B
number_of_cached_scripts:0
allocator_frag_ratio:1.10
allocator_frag_bytes:331536
allocator_rss_ratio:1.70
allocator_rss_bytes:2588672
rss_overhead_ratio:1.93
mem_fragmentation_bytes:8832776
mem_not_counted_for_evict:0
mem_replication_backlog:0
mem_clients_slaves:0
mem_clients_normal:50958
mem_aof_buffer:0
active_defrag_running:0
lazyfree_pending_objects:0

# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1669946176
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:0
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:4640768
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0
module_fork_in_progress:0
module_fork_last_cow_size:0

# Stats
total_connections_received:1818
total_commands_processed:428234
instantaneous_ops_per_sec:0
total_net_input_bytes:25379390
total_net_output_bytes:265337468
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0

# 过期相关信息
expired_keys:0              ## redis 从运行开始计数的过期key的数量
expired_stale_perc:0.00     ## 预估可能将要过期的key的数量
expired_time_cap_reached_count:0    ## 定时扫描过期key的时候，超时的次数，越大说明过期的key较多，CPU有压力
expire_cycle_cpu_milliseconds:69    ## 定时扫描过期key的时候，阻塞主线程的时间。累计值。单位ms
evicted_keys:0                      ## 被驱逐的key。只有内存达到上限后触发淘汰策略，才会被记录。需要特别关心

keyspace_hits:152057
keyspace_misses:2671
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:834               ## 最近一次进行rdb的时候，fork子进程的耗时，单位ms 
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0

# Replication【master和slaveof的信息不太一样】
role:master
connected_slaves:1          # 连接的slaveof的数量
slave0:ip=127.0.0.1,port=7002,state=online,offset=84,lag=0    # slave的基本信息
master_replid:539b0990fec90c24ab9dfee3a1c442392e51c462
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:882      # master的数据进度
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# 【这是slaveof的消息】
role:slave
master_host:127.0.0.1    # master的ip
master_port:7001         # master的端口
master_link_status:up    # master的连接状态
master_last_io_seconds_ago:9
master_sync_in_progress:0
slave_repl_offset:1050   # slaveof的数据进度,小于master的话，说明部分数据还没有同步过去呢
slave_priority:100       # slaveof的优先级，用于master宕机后选举的顺序
slave_read_only:1        # slaveof 是只读的，不能写操作
connected_slaves:0       # 连接的slaveof的数量, slaveof也可以被slaveof。
master_replid:b1900a284495a00827d662583d9848c4c484061e
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:1050
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:1050

# CPU
used_cpu_sys:9.002300
used_cpu_user:8.359404
used_cpu_sys_children:0.000000
used_cpu_user_children:0.056613

# Modules

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=27364,expires=0,avg_ttl=0

# Sentinel【只有哨兵上面才有这个信息】
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=mymaster,status=ok,address=127.0.0.1:7001,slaves=1,sentinels=1
```

### 3.5.配置文件

Redis配置详细解读：https://www.cnblogs.com/guanshan/p/guan2019-10-09_001.html

#### 3.5.1.基本配置

```shell
daemonize no 				是否以后台进程启动，Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程
pidfile /var/run/redis.pid	当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定
databases 16 				设置数据库的数量(默认选中的是database 0)，可以使用SELECT <dbid>命令在连接上指定数据库id
port 6379					指定Redis监听端口，默认端口为6379，（因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字）
bind 127.0.0.1				绑定的主机地址
timeout 300					客户端连接超时时间，如果指定为0，表示关闭该功能
loglevel verbose			指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose
logfile stdout				日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null
```

#### 3.5.2.数据持久化

```shell
# rdb
save <seconds> <changes>	指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合

save 900 1    				#刷新快照到硬盘中，必须满足两者要求才会触发，即900秒之后至少1个关键字发生变化。
save 300 10  				#必须是300秒之后至少10个关键字发生变化。
save 60 10000 				#必须是60秒之后至少10000个关键字发生变化。

stop-writes-on-bgsave-error yes    #后台存储错误停止写。
rdbcompression yes    		#指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大
rdbchecksum yes    			#存储和加载rdb文件时校验。
dbfilename dump.rdb    		#指定本地数据库文件名，默认值为dump.rdb
dir ./    					#指定本地数据库存放目录，rdb文件会写入该目录。

# 数据持久化【aof】（也是种日志模式）
appendonly no	 			#是否仅要日志，默认为no
appendfsync no 				#表示等操作系统进行数据缓存同步到磁盘（快）
appendfsync always 			#表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） 
appendfsync everysec 		#表示每秒同步一次（折衷，默认值）
appendfilename appendonly.aof	#指定更新日志文件名，默认为appendonly.aof
no-appendfsync-on-rewrite no 	#为yes,则其他线程的数据放内存里,合并写入(速度快,容易丢失的多)
auto-AOF-rewrite-percentage 100 #当前aof文件是上次重写是大N%时重写
auto-AOF-rewrite-min-size 64mb 	#aof重写至少要达到的大小
```

#### 3.5.3.主从配置

```shell
slaveof <masterip> <masterport> 	#设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步
masterauth <master-password>   		#当master服务设置了密码保护时，slave服务连接master的密码
slave-serve-stale-data yes  		# 当主从断开或正在复制中,从服务器是否应答
slave-read-only yes 				#从服务器只读
repl-ping-slave-period 10 			#从ping主的时间间隔,秒为单位
repl-timeout 60 					#主从超时时间(超时认为断线了),要比period大
slave-priority 100    				#如果master不能再正常工作，那么会在多个slave中，选择优先值最小的一个slave提升为master，优先值为0表示不能提升为master。
repl-disable-tcp-nodelay no			#主端是否合并数据,大块发送给slave
slave-priority 100 					#从服务器的优先级,当主服挂了,会自动挑slave priority最小的为主服
```

#### 3.5.4.安全

```shell
requirepass foobared 				#设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH <password>命令提供密码，默认关闭
rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #如果公共环境,可以重命名部分敏感命令 如config
```

#### 3.5.5.限制

```shell
maxclients 10000 		#设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，
				#如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回
				#max number of clients reached错误信息
maxmemory <bytes> 		#最大使用内存,Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，
				#当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。
				#Redis新的vm机制，会把Key存放内存，Value会存放在swap区

maxmemory-policy volatile-lru 		#内存到极限后的处理
				volatile-lru 	-> LRU算法删除过期key
				allkeys-lru 	-> LRU算法删除key(不区分过不过期)
				volatile-random -> 随机删除过期key
				allkeys-random 	-> 随机删除key(不区分过不过期)
				volatile-ttl 	-> 删除快过期的key
				noeviction 		-> 不删除,返回错误信息
				#解释 LRU ttl都是近似算法,可以选N个,再比较最适宜T踢出的数据
maxmemory-samples 3

used_memory 859192 					#数据结构的空间
used_memory_rss	7634944 			#实占空间
mem_fragmentation_ratio 8.89 		#前2者的比例,1.N为佳,如果此值过大,说明redis的内存的碎片化严重。
```

#### 3.5.6.vm

```shell
vm-enabled no			#指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，
				#访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）

vm-swap-file /tmp/redis.swap	#虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享

vm-max-memory 0 		#将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的
				#(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0

vm-page-size 32			#Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，
				#vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；
				#如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值

vm-pages 134217728		#设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，在磁盘上每8个pages将消耗1byte的内存。

vm-max-threads 4		#设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4
```

#### 3.5.7.慢查询

```shell
slowlog-log-slower-than 10000 #记录响应时间大于10000微秒的慢查询
slowlog-max-len 128   	# 最多记录128条

# 其他
glueoutputbuf yes				#设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启
hash-max-zipmap-entries 64		#指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法
hash-max-zipmap-value 512
activerehashing yes				#指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）
include /path/to/local.conf		#指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件
```


### 3.6.redis Bulk loading

有的时候需要插入大量数据，Redis就提供了Bulk loading机制，帮我我们插入大量数据。这里数据的格式有两种。
1. Luke协议。文件的格式如下
```text
SET Key0 Value0
SET Key1 Value1
...
SET KeyN ValueN
```
2. Redis协议。文件的格式如下
```text
*<args><cr><lf>
$<len><cr><lf>
<arg0><cr><lf>
<arg1><cr><lf>
...
<argN><cr><lf>
```

插入命令如下：其实就是pipeline
```shell
cat data.txt | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 1000000
```